{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model\n# pprevent annoying tensorflow warning\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\nimport warnings\nwarnings.simplefilter(\"ignore\")\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nimport glob\nimport os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization,Flatten\nimport glob\nfrom pathlib import Path\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:50:23.932084Z","iopub.execute_input":"2022-05-23T05:50:23.932443Z","iopub.status.idle":"2022-05-23T05:50:23.945795Z","shell.execute_reply.started":"2022-05-23T05:50:23.932406Z","shell.execute_reply":"2022-05-23T05:50:23.944796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH='../input/vietnamese-foods/Images/Train'\nTEST_PATH='../input/vietnamese-foods/Images/Test'\nIMAGE_SIZE=(224,224)\nBATCH_SIZE=128 #128\nVALIDATE_PATH='../input/vietnamese-foods/Images/Validate'\nclass_count=30\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:50:25.969838Z","iopub.execute_input":"2022-05-23T05:50:25.970394Z","iopub.status.idle":"2022-05-23T05:50:25.976208Z","shell.execute_reply.started":"2022-05-23T05:50:25.970352Z","shell.execute_reply":"2022-05-23T05:50:25.975483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 40, \n    width_shift_range = 0.2, \n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True)\n\nvalidate_generator = ImageDataGenerator(rescale=1./255)\ntest_generator = ImageDataGenerator(rescale=1./255)\n\ntrain_data = train_generator.flow_from_directory(TRAIN_PATH, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\nvalidate_data = validate_generator.flow_from_directory(VALIDATE_PATH, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\ntest_data = test_generator.flow_from_directory(TEST_PATH, target_size=IMAGE_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:48:33.809457Z","iopub.execute_input":"2022-05-23T05:48:33.810569Z","iopub.status.idle":"2022-05-23T05:48:36.968079Z","shell.execute_reply.started":"2022-05-23T05:48:33.810512Z","shell.execute_reply":"2022-05-23T05:48:36.966833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create 2 useful callbacks, one to control the learning rate, and one to control early stopping based on validation loss\nrlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n# estop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4, verbose=1,restore_best_weights=True)\n# #rlronp,\n# callbacks=[estop]","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:50:37.217797Z","iopub.execute_input":"2022-05-23T05:50:37.218223Z","iopub.status.idle":"2022-05-23T05:50:37.224767Z","shell.execute_reply.started":"2022-05-23T05:50:37.218185Z","shell.execute_reply":"2022-05-23T05:50:37.223496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = VGG19(weights='imagenet', include_top=False)\nlast_output = pretrained_model.output\nx = GlobalAveragePooling2D()(last_output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.4)(x)\noutputs = Dense(30, activation='softmax')(x)\nmodel = Model(inputs=pretrained_model.input, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:53:07.110524Z","iopub.execute_input":"2022-05-23T05:53:07.110857Z","iopub.status.idle":"2022-05-23T05:53:08.904198Z","shell.execute_reply.started":"2022-05-23T05:53:07.110823Z","shell.execute_reply":"2022-05-23T05:53:08.90298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in pretrained_model.layers: layer.trainable = False #,\nmodel.compile(optimizer='rmsprop',loss='mse', metrics=['accuracy']) ","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:54:10.830091Z","iopub.execute_input":"2022-05-23T05:54:10.830673Z","iopub.status.idle":"2022-05-23T05:54:10.846309Z","shell.execute_reply.started":"2022-05-23T05:54:10.830634Z","shell.execute_reply":"2022-05-23T05:54:10.844938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:54:14.010257Z","iopub.execute_input":"2022-05-23T05:54:14.010581Z","iopub.status.idle":"2022-05-23T05:54:14.015544Z","shell.execute_reply.started":"2022-05-23T05:54:14.010547Z","shell.execute_reply":"2022-05-23T05:54:14.014761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\nepochs=20\nhistory=model.fit(x=train_data ,epochs=epochs, verbose=1,validation_data=validate_data,\n                  callbacks = [rlronp, early_stopping],shuffle=False, initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T05:54:15.476963Z","iopub.execute_input":"2022-05-23T05:54:15.477665Z","iopub.status.idle":"2022-05-23T05:55:54.671855Z","shell.execute_reply.started":"2022-05-23T05:54:15.477623Z","shell.execute_reply":"2022-05-23T05:55:54.670654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vẽ lại quá trình học\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train','Validation'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import load_img, img_to_array\nimport numpy as np\nimport matplotlib.pyplot as plt\nfilename = \"../input/fruitdataset/train/tomato/Image_11.jpg\"\n\nimg = load_img(filename,target_size=(224,224))\nimg_show = plt.imshow(img)\nplt.show()\nimg = img_to_array(img)\nimg = img.reshape(1,224,224,3)\nimg = img.astype('float32')\nimg = img/255\nkq=np.argmax(model.predict(img),axis=-1)\nif(kq==0):\n    print(\"Banh beo\")\nif(kq==1):\n    print(\"Bot loc\")\nif(kq==2):\n    print(\"Banh Can\")\nif(kq==3):\n    print(\"Banh canh\")\nif(kq==4):\n    print(\"Banh chung\")\nif(kq==5):\n    print(\"Banh cuon\")\nif(kq==6):\n    print(\"Banh duc\")\nif(kq==7):\n    print(\"Banh gio\")\nif(kq==8):\n    print(\"Banh khot\")\nif(kq==9):\n    print(\"Banh mi\")\nif(kq==10):\n    print(\"Banh pia\")\n","metadata":{},"execution_count":null,"outputs":[]}]}